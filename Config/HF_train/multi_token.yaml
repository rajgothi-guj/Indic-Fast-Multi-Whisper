model_name: "openai/whisper-medium"
language: "Gujarati"
sampling_rate: 16000
num_proc: 2
train_strategy: "steps"
learning_rate:  5.00e-5
warmup: 500
train_batchsize: 16
eval_batchsize: 32
num_epochs: 3
# num_steps: 1000000
resume_from_ckpt: null
prompting: False

tokenizer_name : 'tokenizer/all_tokenizer_125'

output_dir: "trained_model/Alltokenized_Medium_125"

train_datasets:
  - "/hdd2/raj/preprocess/hindi_kathbath_medium_Alltokenized_125"
  - "/hdd2/raj/preprocess/gujarati_kathbath_medium_Alltokenized_125"
  - "/hdd2/raj/preprocess/marathi_kathbath_medium_Alltokenized_125"
  - "/hdd2/raj/preprocess/bengali_kathbath_medium_Alltokenized_125"
  - "/hdd2/raj/preprocess/tamil_kathbath_medium_Alltokenized_125"
  - "/hdd2/raj/preprocess/telugu_kathbath_medium_Alltokenized_125"
  - "/hdd2/raj/preprocess/kannada_kathbath_medium_Alltokenized_125"  
  - "/hdd2/raj/preprocess/malayalam_kathbath_medium_Alltokenized_125"  
  # Add more datasets as needed
# train_dataset_configs:
#   - "config1"
#   - "config2"
#   # Add more configs as needed
train_dataset_splits:
  - "train"
  - "train"
  - "train"
  - "train"
  - "train"
  - "train"
  - "train"
  - "train"
  # Add more splits as needed
# train_dataset_text_columns:
#   - "text_column1"
#   - "text_column2"
#   # Add more text columns as needed
eval_datasets:
  - "/hdd2/raj/preprocess/hindi_kathbath_medium_Alltokenized_125"
  - "/hdd2/raj/preprocess/gujarati_kathbath_medium_Alltokenized_125"
  - "/hdd2/raj/preprocess/marathi_kathbath_medium_Alltokenized_125"
  - "/hdd2/raj/preprocess/bengali_kathbath_medium_Alltokenized_125"
  - "/hdd2/raj/preprocess/tamil_kathbath_medium_Alltokenized_125"
  - "/hdd2/raj/preprocess/telugu_kathbath_medium_Alltokenized_125"
  - "/hdd2/raj/preprocess/kannada_kathbath_medium_Alltokenized_125"  
  - "/hdd2/raj/preprocess/malayalam_kathbath_medium_Alltokenized_125"  
  # Add more datasets as needed
# eval_dataset_configs:
#   - "config1"
#   - "config2"
#   # Add more configs as needed
eval_dataset_splits:
  - "validation"
  - "validation"
  - "validation"
  - "validation"
  - "validation"
  - "validation"
  - "validation"
  - "validation"
  # Add more splits as needed
# eval_dataset_text_columns:
#   - "text_column1"
#   - "text_column2"
  # Add more text columns as needed
seed: 1